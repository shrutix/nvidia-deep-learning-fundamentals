{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t      snapshot_iter_270.caffemodel\r\n",
      "deploy.prototxt\t\t      snapshot_iter_270.solverstate\r\n",
      "original.prototxt\t      snapshot_iter_54.caffemodel\r\n",
      "snapshot_iter_108.caffemodel  solver.prototxt\r\n",
      "snapshot_iter_162.caffemodel  status.pickle\r\n",
      "snapshot_iter_216.caffemodel  train_val.prototxt\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_JOB_DIR = '/dli/data/digits/20190922-225346-d93f'\n",
    "!ls $MODEL_JOB_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 23:27:17.698556   267 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0922 23:27:17.699235   267 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0922 23:27:17.699292   267 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0922 23:27:17.699414   267 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0922 23:27:17.699429   267 _caffe.cpp:175] Net('/dli/data/digits/20190922-225346-d93f/deploy.prototxt', 1, weights='/dli/data/digits/20190922-225346-d93f/snapshot_iter_270.caffemodel')\n",
      "I0922 23:27:17.699738   267 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190922-225346-d93f/deploy.prototxt\n",
      "I0922 23:27:17.699769   267 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0922 23:27:17.699779   267 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0922 23:27:17.708988   267 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0922 23:27:17.709414   267 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0922 23:27:17.709429   267 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0922 23:27:17.709437   267 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0922 23:27:17.709450   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:17.709463   267 net.cpp:199] Created Layer input (0)\n",
      "I0922 23:27:17.709478   267 net.cpp:541] input -> data\n",
      "I0922 23:27:17.710137   267 net.cpp:259] Setting up input\n",
      "I0922 23:27:17.710162   267 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0922 23:27:17.710177   267 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0922 23:27:17.710188   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:17.710222   267 net.cpp:199] Created Layer conv1 (1)\n",
      "I0922 23:27:17.710234   267 net.cpp:571] conv1 <- data\n",
      "I0922 23:27:17.710243   267 net.cpp:541] conv1 -> conv1\n",
      "I0922 23:27:18.223244   267 net.cpp:259] Setting up conv1\n",
      "I0922 23:27:18.223299   267 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0922 23:27:18.223330   267 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0922 23:27:18.223348   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.223363   267 net.cpp:199] Created Layer relu1 (2)\n",
      "I0922 23:27:18.223376   267 net.cpp:571] relu1 <- conv1\n",
      "I0922 23:27:18.223385   267 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0922 23:27:18.223412   267 net.cpp:259] Setting up relu1\n",
      "I0922 23:27:18.223423   267 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0922 23:27:18.223438   267 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0922 23:27:18.223448   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.223475   267 net.cpp:199] Created Layer norm1 (3)\n",
      "I0922 23:27:18.223485   267 net.cpp:571] norm1 <- conv1\n",
      "I0922 23:27:18.223497   267 net.cpp:541] norm1 -> norm1\n",
      "I0922 23:27:18.223559   267 net.cpp:259] Setting up norm1\n",
      "I0922 23:27:18.223577   267 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0922 23:27:18.223584   267 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0922 23:27:18.223596   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.223639   267 net.cpp:199] Created Layer pool1 (4)\n",
      "I0922 23:27:18.223652   267 net.cpp:571] pool1 <- norm1\n",
      "I0922 23:27:18.223662   267 net.cpp:541] pool1 -> pool1\n",
      "I0922 23:27:18.223726   267 net.cpp:259] Setting up pool1\n",
      "I0922 23:27:18.223742   267 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0922 23:27:18.223750   267 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0922 23:27:18.223762   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.223778   267 net.cpp:199] Created Layer conv2 (5)\n",
      "I0922 23:27:18.223789   267 net.cpp:571] conv2 <- pool1\n",
      "I0922 23:27:18.223796   267 net.cpp:541] conv2 -> conv2\n",
      "I0922 23:27:18.230662   267 net.cpp:259] Setting up conv2\n",
      "I0922 23:27:18.230688   267 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0922 23:27:18.230705   267 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0922 23:27:18.230718   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.230727   267 net.cpp:199] Created Layer relu2 (6)\n",
      "I0922 23:27:18.230739   267 net.cpp:571] relu2 <- conv2\n",
      "I0922 23:27:18.230746   267 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0922 23:27:18.230762   267 net.cpp:259] Setting up relu2\n",
      "I0922 23:27:18.230773   267 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0922 23:27:18.230783   267 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0922 23:27:18.230794   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.230810   267 net.cpp:199] Created Layer norm2 (7)\n",
      "I0922 23:27:18.230820   267 net.cpp:571] norm2 <- conv2\n",
      "I0922 23:27:18.230831   267 net.cpp:541] norm2 -> norm2\n",
      "I0922 23:27:18.230883   267 net.cpp:259] Setting up norm2\n",
      "I0922 23:27:18.230901   267 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0922 23:27:18.230911   267 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0922 23:27:18.230922   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.230938   267 net.cpp:199] Created Layer pool2 (8)\n",
      "I0922 23:27:18.230950   267 net.cpp:571] pool2 <- norm2\n",
      "I0922 23:27:18.230957   267 net.cpp:541] pool2 -> pool2\n",
      "I0922 23:27:18.231014   267 net.cpp:259] Setting up pool2\n",
      "I0922 23:27:18.231029   267 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0922 23:27:18.231040   267 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0922 23:27:18.231051   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.231070   267 net.cpp:199] Created Layer conv3 (9)\n",
      "I0922 23:27:18.231081   267 net.cpp:571] conv3 <- pool2\n",
      "I0922 23:27:18.231092   267 net.cpp:541] conv3 -> conv3\n",
      "I0922 23:27:18.246556   267 net.cpp:259] Setting up conv3\n",
      "I0922 23:27:18.246582   267 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0922 23:27:18.246598   267 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0922 23:27:18.246610   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.246619   267 net.cpp:199] Created Layer relu3 (10)\n",
      "I0922 23:27:18.246630   267 net.cpp:571] relu3 <- conv3\n",
      "I0922 23:27:18.246644   267 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0922 23:27:18.246659   267 net.cpp:259] Setting up relu3\n",
      "I0922 23:27:18.246670   267 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0922 23:27:18.246680   267 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0922 23:27:18.246691   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.246711   267 net.cpp:199] Created Layer conv4 (11)\n",
      "I0922 23:27:18.246721   267 net.cpp:571] conv4 <- conv3\n",
      "I0922 23:27:18.246731   267 net.cpp:541] conv4 -> conv4\n",
      "I0922 23:27:18.258899   267 net.cpp:259] Setting up conv4\n",
      "I0922 23:27:18.258924   267 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0922 23:27:18.258965   267 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0922 23:27:18.258973   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.258986   267 net.cpp:199] Created Layer relu4 (12)\n",
      "I0922 23:27:18.258999   267 net.cpp:571] relu4 <- conv4\n",
      "I0922 23:27:18.259006   267 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0922 23:27:18.259023   267 net.cpp:259] Setting up relu4\n",
      "I0922 23:27:18.259035   267 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0922 23:27:18.259044   267 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0922 23:27:18.259055   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.259075   267 net.cpp:199] Created Layer conv5 (13)\n",
      "I0922 23:27:18.259085   267 net.cpp:571] conv5 <- conv4\n",
      "I0922 23:27:18.259093   267 net.cpp:541] conv5 -> conv5\n",
      "I0922 23:27:18.267051   267 net.cpp:259] Setting up conv5\n",
      "I0922 23:27:18.267076   267 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0922 23:27:18.267096   267 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0922 23:27:18.267109   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.267117   267 net.cpp:199] Created Layer relu5 (14)\n",
      "I0922 23:27:18.267128   267 net.cpp:571] relu5 <- conv5\n",
      "I0922 23:27:18.267135   267 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0922 23:27:18.267150   267 net.cpp:259] Setting up relu5\n",
      "I0922 23:27:18.267163   267 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0922 23:27:18.267168   267 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0922 23:27:18.267179   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.267197   267 net.cpp:199] Created Layer pool5 (15)\n",
      "I0922 23:27:18.267207   267 net.cpp:571] pool5 <- conv5\n",
      "I0922 23:27:18.267220   267 net.cpp:541] pool5 -> pool5\n",
      "I0922 23:27:18.267289   267 net.cpp:259] Setting up pool5\n",
      "I0922 23:27:18.267307   267 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0922 23:27:18.267318   267 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0922 23:27:18.267333   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.267354   267 net.cpp:199] Created Layer fc6 (16)\n",
      "I0922 23:27:18.267365   267 net.cpp:571] fc6 <- pool5\n",
      "I0922 23:27:18.267372   267 net.cpp:541] fc6 -> fc6\n",
      "I0922 23:27:18.938688   267 net.cpp:259] Setting up fc6\n",
      "I0922 23:27:18.938731   267 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0922 23:27:18.938757   267 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0922 23:27:18.938771   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.938788   267 net.cpp:199] Created Layer relu6 (17)\n",
      "I0922 23:27:18.938800   267 net.cpp:571] relu6 <- fc6\n",
      "I0922 23:27:18.938815   267 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0922 23:27:18.938835   267 net.cpp:259] Setting up relu6\n",
      "I0922 23:27:18.938848   267 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0922 23:27:18.938859   267 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0922 23:27:18.938870   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.938889   267 net.cpp:199] Created Layer drop6 (18)\n",
      "I0922 23:27:18.938900   267 net.cpp:571] drop6 <- fc6\n",
      "I0922 23:27:18.938911   267 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0922 23:27:18.973291   267 net.cpp:259] Setting up drop6\n",
      "I0922 23:27:18.973321   267 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0922 23:27:18.973333   267 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0922 23:27:18.973343   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:18.973361   267 net.cpp:199] Created Layer fc7 (19)\n",
      "I0922 23:27:18.973402   267 net.cpp:571] fc7 <- fc6\n",
      "I0922 23:27:18.973417   267 net.cpp:541] fc7 -> fc7\n",
      "I0922 23:27:19.272250   267 net.cpp:259] Setting up fc7\n",
      "I0922 23:27:19.272298   267 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0922 23:27:19.272316   267 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0922 23:27:19.272331   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:19.272343   267 net.cpp:199] Created Layer relu7 (20)\n",
      "I0922 23:27:19.272357   267 net.cpp:571] relu7 <- fc7\n",
      "I0922 23:27:19.272372   267 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0922 23:27:19.272393   267 net.cpp:259] Setting up relu7\n",
      "I0922 23:27:19.272405   267 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0922 23:27:19.272416   267 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0922 23:27:19.272428   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:19.272446   267 net.cpp:199] Created Layer drop7 (21)\n",
      "I0922 23:27:19.272456   267 net.cpp:571] drop7 <- fc7\n",
      "I0922 23:27:19.272469   267 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0922 23:27:19.306931   267 net.cpp:259] Setting up drop7\n",
      "I0922 23:27:19.306958   267 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0922 23:27:19.306970   267 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0922 23:27:19.306984   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:19.307001   267 net.cpp:199] Created Layer fc8 (22)\n",
      "I0922 23:27:19.307013   267 net.cpp:571] fc8 <- fc7\n",
      "I0922 23:27:19.307021   267 net.cpp:541] fc8 -> fc8\n",
      "I0922 23:27:19.307902   267 net.cpp:259] Setting up fc8\n",
      "I0922 23:27:19.307926   267 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0922 23:27:19.307940   267 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0922 23:27:19.307953   267 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:19.307968   267 net.cpp:199] Created Layer softmax (23)\n",
      "I0922 23:27:19.307979   267 net.cpp:571] softmax <- fc8\n",
      "I0922 23:27:19.307986   267 net.cpp:541] softmax -> softmax\n",
      "I0922 23:27:19.308068   267 net.cpp:259] Setting up softmax\n",
      "I0922 23:27:19.308084   267 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0922 23:27:19.308092   267 net.cpp:337] softmax does not need backward computation.\n",
      "I0922 23:27:19.308104   267 net.cpp:337] fc8 does not need backward computation.\n",
      "I0922 23:27:19.308109   267 net.cpp:337] drop7 does not need backward computation.\n",
      "I0922 23:27:19.308120   267 net.cpp:337] relu7 does not need backward computation.\n",
      "I0922 23:27:19.308125   267 net.cpp:337] fc7 does not need backward computation.\n",
      "I0922 23:27:19.308135   267 net.cpp:337] drop6 does not need backward computation.\n",
      "I0922 23:27:19.308140   267 net.cpp:337] relu6 does not need backward computation.\n",
      "I0922 23:27:19.308151   267 net.cpp:337] fc6 does not need backward computation.\n",
      "I0922 23:27:19.308157   267 net.cpp:337] pool5 does not need backward computation.\n",
      "I0922 23:27:19.308168   267 net.cpp:337] relu5 does not need backward computation.\n",
      "I0922 23:27:19.308174   267 net.cpp:337] conv5 does not need backward computation.\n",
      "I0922 23:27:19.308182   267 net.cpp:337] relu4 does not need backward computation.\n",
      "I0922 23:27:19.308190   267 net.cpp:337] conv4 does not need backward computation.\n",
      "I0922 23:27:19.308195   267 net.cpp:337] relu3 does not need backward computation.\n",
      "I0922 23:27:19.308207   267 net.cpp:337] conv3 does not need backward computation.\n",
      "I0922 23:27:19.308213   267 net.cpp:337] pool2 does not need backward computation.\n",
      "I0922 23:27:19.308220   267 net.cpp:337] norm2 does not need backward computation.\n",
      "I0922 23:27:19.308226   267 net.cpp:337] relu2 does not need backward computation.\n",
      "I0922 23:27:19.308238   267 net.cpp:337] conv2 does not need backward computation.\n",
      "I0922 23:27:19.308251   267 net.cpp:337] pool1 does not need backward computation.\n",
      "I0922 23:27:19.308287   267 net.cpp:337] norm1 does not need backward computation.\n",
      "I0922 23:27:19.308298   267 net.cpp:337] relu1 does not need backward computation.\n",
      "I0922 23:27:19.308305   267 net.cpp:337] conv1 does not need backward computation.\n",
      "I0922 23:27:19.308315   267 net.cpp:337] input does not need backward computation.\n",
      "I0922 23:27:19.308324   267 net.cpp:379] This network produces output softmax\n",
      "I0922 23:27:19.308357   267 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0922 23:27:19.308367   267 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0922 23:27:19.308378   267 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0922 23:27:19.308389   267 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0922 23:27:19.308399   267 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0922 23:27:19.308409   267 net.cpp:420] Network initialization done.\n",
      "I0922 23:27:19.414242   267 net.cpp:1129] Ignoring source layer train-data\n",
      "I0922 23:27:19.414278   267 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0922 23:27:19.414364   267 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.414379   267 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0922 23:27:19.414391   267 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0922 23:27:19.414402   267 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0922 23:27:19.414577   267 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.414590   267 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0922 23:27:19.414597   267 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0922 23:27:19.414607   267 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0922 23:27:19.415062   267 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.415077   267 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0922 23:27:19.415426   267 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.415439   267 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0922 23:27:19.415685   267 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.415699   267 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0922 23:27:19.415705   267 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:19.433219   267 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.433254   267 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0922 23:27:19.433266   267 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:19.440980   267 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0922 23:27:19.441009   267 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0922 23:27:19.441013   267 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:19.441045   267 net.cpp:1129] Ignoring source layer loss\n",
      "whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 23:27:26.665884   282 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0922 23:27:26.666586   282 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0922 23:27:26.666644   282 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0922 23:27:26.666764   282 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0922 23:27:26.666779   282 _caffe.cpp:175] Net('/dli/data/digits/20190922-225346-d93f/deploy.prototxt', 1, weights='/dli/data/digits/20190922-225346-d93f/snapshot_iter_270.caffemodel')\n",
      "I0922 23:27:26.667068   282 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190922-225346-d93f/deploy.prototxt\n",
      "I0922 23:27:26.667095   282 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0922 23:27:26.667106   282 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0922 23:27:26.676404   282 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0922 23:27:26.676841   282 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0922 23:27:26.676859   282 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0922 23:27:26.676870   282 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0922 23:27:26.676887   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:26.676918   282 net.cpp:199] Created Layer input (0)\n",
      "I0922 23:27:26.676936   282 net.cpp:541] input -> data\n",
      "I0922 23:27:26.677574   282 net.cpp:259] Setting up input\n",
      "I0922 23:27:26.677603   282 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0922 23:27:26.677625   282 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0922 23:27:26.677639   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:26.677668   282 net.cpp:199] Created Layer conv1 (1)\n",
      "I0922 23:27:26.677680   282 net.cpp:571] conv1 <- data\n",
      "I0922 23:27:26.677696   282 net.cpp:541] conv1 -> conv1\n",
      "I0922 23:27:27.191854   282 net.cpp:259] Setting up conv1\n",
      "I0922 23:27:27.191901   282 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0922 23:27:27.191927   282 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0922 23:27:27.191943   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.191958   282 net.cpp:199] Created Layer relu1 (2)\n",
      "I0922 23:27:27.191969   282 net.cpp:571] relu1 <- conv1\n",
      "I0922 23:27:27.191978   282 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0922 23:27:27.191998   282 net.cpp:259] Setting up relu1\n",
      "I0922 23:27:27.192009   282 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0922 23:27:27.192025   282 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0922 23:27:27.192042   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.192072   282 net.cpp:199] Created Layer norm1 (3)\n",
      "I0922 23:27:27.192085   282 net.cpp:571] norm1 <- conv1\n",
      "I0922 23:27:27.192095   282 net.cpp:541] norm1 -> norm1\n",
      "I0922 23:27:27.192164   282 net.cpp:259] Setting up norm1\n",
      "I0922 23:27:27.192185   282 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0922 23:27:27.192198   282 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0922 23:27:27.192212   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.192263   282 net.cpp:199] Created Layer pool1 (4)\n",
      "I0922 23:27:27.192279   282 net.cpp:571] pool1 <- norm1\n",
      "I0922 23:27:27.192291   282 net.cpp:541] pool1 -> pool1\n",
      "I0922 23:27:27.192366   282 net.cpp:259] Setting up pool1\n",
      "I0922 23:27:27.192385   282 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0922 23:27:27.192404   282 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0922 23:27:27.192415   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.192445   282 net.cpp:199] Created Layer conv2 (5)\n",
      "I0922 23:27:27.192458   282 net.cpp:571] conv2 <- pool1\n",
      "I0922 23:27:27.192471   282 net.cpp:541] conv2 -> conv2\n",
      "I0922 23:27:27.199373   282 net.cpp:259] Setting up conv2\n",
      "I0922 23:27:27.199403   282 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0922 23:27:27.199431   282 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0922 23:27:27.199445   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.199455   282 net.cpp:199] Created Layer relu2 (6)\n",
      "I0922 23:27:27.199466   282 net.cpp:571] relu2 <- conv2\n",
      "I0922 23:27:27.199473   282 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0922 23:27:27.199488   282 net.cpp:259] Setting up relu2\n",
      "I0922 23:27:27.199501   282 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0922 23:27:27.199515   282 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0922 23:27:27.199530   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.199554   282 net.cpp:199] Created Layer norm2 (7)\n",
      "I0922 23:27:27.199566   282 net.cpp:571] norm2 <- conv2\n",
      "I0922 23:27:27.199582   282 net.cpp:541] norm2 -> norm2\n",
      "I0922 23:27:27.199640   282 net.cpp:259] Setting up norm2\n",
      "I0922 23:27:27.199659   282 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0922 23:27:27.199676   282 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0922 23:27:27.199690   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.199712   282 net.cpp:199] Created Layer pool2 (8)\n",
      "I0922 23:27:27.199725   282 net.cpp:571] pool2 <- norm2\n",
      "I0922 23:27:27.199740   282 net.cpp:541] pool2 -> pool2\n",
      "I0922 23:27:27.199802   282 net.cpp:259] Setting up pool2\n",
      "I0922 23:27:27.199820   282 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0922 23:27:27.199837   282 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0922 23:27:27.199851   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.199877   282 net.cpp:199] Created Layer conv3 (9)\n",
      "I0922 23:27:27.199888   282 net.cpp:571] conv3 <- pool2\n",
      "I0922 23:27:27.199904   282 net.cpp:541] conv3 -> conv3\n",
      "I0922 23:27:27.215567   282 net.cpp:259] Setting up conv3\n",
      "I0922 23:27:27.215596   282 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0922 23:27:27.215617   282 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0922 23:27:27.215633   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.215652   282 net.cpp:199] Created Layer relu3 (10)\n",
      "I0922 23:27:27.215667   282 net.cpp:571] relu3 <- conv3\n",
      "I0922 23:27:27.215682   282 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0922 23:27:27.215701   282 net.cpp:259] Setting up relu3\n",
      "I0922 23:27:27.215716   282 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0922 23:27:27.215731   282 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0922 23:27:27.215746   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.215771   282 net.cpp:199] Created Layer conv4 (11)\n",
      "I0922 23:27:27.215783   282 net.cpp:571] conv4 <- conv3\n",
      "I0922 23:27:27.215800   282 net.cpp:541] conv4 -> conv4\n",
      "I0922 23:27:27.228119   282 net.cpp:259] Setting up conv4\n",
      "I0922 23:27:27.228149   282 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0922 23:27:27.228196   282 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0922 23:27:27.228211   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.228229   282 net.cpp:199] Created Layer relu4 (12)\n",
      "I0922 23:27:27.228245   282 net.cpp:571] relu4 <- conv4\n",
      "I0922 23:27:27.228261   282 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0922 23:27:27.228279   282 net.cpp:259] Setting up relu4\n",
      "I0922 23:27:27.228296   282 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0922 23:27:27.228312   282 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0922 23:27:27.228327   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.228351   282 net.cpp:199] Created Layer conv5 (13)\n",
      "I0922 23:27:27.228364   282 net.cpp:571] conv5 <- conv4\n",
      "I0922 23:27:27.228380   282 net.cpp:541] conv5 -> conv5\n",
      "I0922 23:27:27.236405   282 net.cpp:259] Setting up conv5\n",
      "I0922 23:27:27.236433   282 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0922 23:27:27.236455   282 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0922 23:27:27.236472   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.236490   282 net.cpp:199] Created Layer relu5 (14)\n",
      "I0922 23:27:27.236505   282 net.cpp:571] relu5 <- conv5\n",
      "I0922 23:27:27.236519   282 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0922 23:27:27.236539   282 net.cpp:259] Setting up relu5\n",
      "I0922 23:27:27.236554   282 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0922 23:27:27.236569   282 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0922 23:27:27.236583   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.236603   282 net.cpp:199] Created Layer pool5 (15)\n",
      "I0922 23:27:27.236616   282 net.cpp:571] pool5 <- conv5\n",
      "I0922 23:27:27.236631   282 net.cpp:541] pool5 -> pool5\n",
      "I0922 23:27:27.236698   282 net.cpp:259] Setting up pool5\n",
      "I0922 23:27:27.236719   282 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0922 23:27:27.236735   282 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0922 23:27:27.236750   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.236773   282 net.cpp:199] Created Layer fc6 (16)\n",
      "I0922 23:27:27.236785   282 net.cpp:571] fc6 <- pool5\n",
      "I0922 23:27:27.236801   282 net.cpp:541] fc6 -> fc6\n",
      "I0922 23:27:27.909232   282 net.cpp:259] Setting up fc6\n",
      "I0922 23:27:27.909277   282 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0922 23:27:27.909296   282 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0922 23:27:27.909312   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.909324   282 net.cpp:199] Created Layer relu6 (17)\n",
      "I0922 23:27:27.909337   282 net.cpp:571] relu6 <- fc6\n",
      "I0922 23:27:27.909353   282 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0922 23:27:27.909371   282 net.cpp:259] Setting up relu6\n",
      "I0922 23:27:27.909384   282 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0922 23:27:27.909394   282 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0922 23:27:27.909405   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.909431   282 net.cpp:199] Created Layer drop6 (18)\n",
      "I0922 23:27:27.909442   282 net.cpp:571] drop6 <- fc6\n",
      "I0922 23:27:27.909453   282 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0922 23:27:27.943873   282 net.cpp:259] Setting up drop6\n",
      "I0922 23:27:27.943902   282 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0922 23:27:27.943914   282 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0922 23:27:27.943928   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:27.943948   282 net.cpp:199] Created Layer fc7 (19)\n",
      "I0922 23:27:27.943985   282 net.cpp:571] fc7 <- fc6\n",
      "I0922 23:27:27.943994   282 net.cpp:541] fc7 -> fc7\n",
      "I0922 23:27:28.243604   282 net.cpp:259] Setting up fc7\n",
      "I0922 23:27:28.243649   282 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0922 23:27:28.243667   282 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0922 23:27:28.243682   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:28.243695   282 net.cpp:199] Created Layer relu7 (20)\n",
      "I0922 23:27:28.243707   282 net.cpp:571] relu7 <- fc7\n",
      "I0922 23:27:28.243716   282 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0922 23:27:28.243736   282 net.cpp:259] Setting up relu7\n",
      "I0922 23:27:28.243747   282 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0922 23:27:28.243757   282 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0922 23:27:28.243768   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:28.243780   282 net.cpp:199] Created Layer drop7 (21)\n",
      "I0922 23:27:28.243789   282 net.cpp:571] drop7 <- fc7\n",
      "I0922 23:27:28.243796   282 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0922 23:27:28.278255   282 net.cpp:259] Setting up drop7\n",
      "I0922 23:27:28.278286   282 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0922 23:27:28.278300   282 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0922 23:27:28.278316   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:28.278332   282 net.cpp:199] Created Layer fc8 (22)\n",
      "I0922 23:27:28.278344   282 net.cpp:571] fc8 <- fc7\n",
      "I0922 23:27:28.278357   282 net.cpp:541] fc8 -> fc8\n",
      "I0922 23:27:28.279256   282 net.cpp:259] Setting up fc8\n",
      "I0922 23:27:28.279280   282 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0922 23:27:28.279299   282 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0922 23:27:28.279306   282 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0922 23:27:28.279328   282 net.cpp:199] Created Layer softmax (23)\n",
      "I0922 23:27:28.279340   282 net.cpp:571] softmax <- fc8\n",
      "I0922 23:27:28.279347   282 net.cpp:541] softmax -> softmax\n",
      "I0922 23:27:28.279438   282 net.cpp:259] Setting up softmax\n",
      "I0922 23:27:28.279453   282 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0922 23:27:28.279461   282 net.cpp:337] softmax does not need backward computation.\n",
      "I0922 23:27:28.279472   282 net.cpp:337] fc8 does not need backward computation.\n",
      "I0922 23:27:28.279477   282 net.cpp:337] drop7 does not need backward computation.\n",
      "I0922 23:27:28.279489   282 net.cpp:337] relu7 does not need backward computation.\n",
      "I0922 23:27:28.279495   282 net.cpp:337] fc7 does not need backward computation.\n",
      "I0922 23:27:28.279503   282 net.cpp:337] drop6 does not need backward computation.\n",
      "I0922 23:27:28.279510   282 net.cpp:337] relu6 does not need backward computation.\n",
      "I0922 23:27:28.279520   282 net.cpp:337] fc6 does not need backward computation.\n",
      "I0922 23:27:28.279525   282 net.cpp:337] pool5 does not need backward computation.\n",
      "I0922 23:27:28.279532   282 net.cpp:337] relu5 does not need backward computation.\n",
      "I0922 23:27:28.279541   282 net.cpp:337] conv5 does not need backward computation.\n",
      "I0922 23:27:28.279551   282 net.cpp:337] relu4 does not need backward computation.\n",
      "I0922 23:27:28.279556   282 net.cpp:337] conv4 does not need backward computation.\n",
      "I0922 23:27:28.279562   282 net.cpp:337] relu3 does not need backward computation.\n",
      "I0922 23:27:28.279568   282 net.cpp:337] conv3 does not need backward computation.\n",
      "I0922 23:27:28.279577   282 net.cpp:337] pool2 does not need backward computation.\n",
      "I0922 23:27:28.279584   282 net.cpp:337] norm2 does not need backward computation.\n",
      "I0922 23:27:28.279592   282 net.cpp:337] relu2 does not need backward computation.\n",
      "I0922 23:27:28.279601   282 net.cpp:337] conv2 does not need backward computation.\n",
      "I0922 23:27:28.279608   282 net.cpp:337] pool1 does not need backward computation.\n",
      "I0922 23:27:28.279642   282 net.cpp:337] norm1 does not need backward computation.\n",
      "I0922 23:27:28.279656   282 net.cpp:337] relu1 does not need backward computation.\n",
      "I0922 23:27:28.279662   282 net.cpp:337] conv1 does not need backward computation.\n",
      "I0922 23:27:28.279672   282 net.cpp:337] input does not need backward computation.\n",
      "I0922 23:27:28.279683   282 net.cpp:379] This network produces output softmax\n",
      "I0922 23:27:28.279709   282 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0922 23:27:28.279721   282 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0922 23:27:28.279731   282 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0922 23:27:28.279742   282 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0922 23:27:28.279752   282 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0922 23:27:28.279762   282 net.cpp:420] Network initialization done.\n",
      "I0922 23:27:28.384290   282 net.cpp:1129] Ignoring source layer train-data\n",
      "I0922 23:27:28.384330   282 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0922 23:27:28.384410   282 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.384424   282 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0922 23:27:28.384430   282 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0922 23:27:28.384435   282 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0922 23:27:28.384611   282 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.384625   282 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0922 23:27:28.384636   282 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0922 23:27:28.384640   282 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0922 23:27:28.385087   282 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.385100   282 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0922 23:27:28.385442   282 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.385455   282 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0922 23:27:28.385689   282 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.385702   282 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0922 23:27:28.385709   282 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:28.403280   282 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.403311   282 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0922 23:27:28.403322   282 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:28.411119   282 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0922 23:27:28.411146   282 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0922 23:27:28.411151   282 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0922 23:27:28.411175   282 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
